{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Relatorio T√©cnico Referente a Mat√©ria de T√©cnicas de Pesquisa Experimental\n",
    "  \n",
    "**Tema:** Analise da Varia√ß√£o de Par√¢metros na Impress√£o 3D de Filamentos Polim√©ricos  \n",
    "**Prof¬∫:** Pedro Bastos Costa  \n",
    "**Universidade Federal de Minas Gerais - UFMG**\n",
    "\n",
    "**Membros:**\n",
    "* Guilherme de Paula R√∫bio  \n",
    "* Matheus Ungaretti Borges  \n",
    "* Daniel Affonso Vasconcelos  \n",
    "\n",
    "## *Importa√ß√£o de Bibliotecas*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy.stats as st \n",
    "import scipy.linalg as ln\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "source": [
    "## ***Fu√ß√µes Auxiliares Criadas***  \n",
    "\n",
    "* **Fun√ß√£o**: Teste de hip√≥tese bicaudal, distribui√ß√£o F"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "def F_bicaudal_hypoteses (F :float, alpha :float, dn :float, dd :float):\n",
    "    '''\n",
    "        Fun√ß√£o de teste de hip√≥tese de um teste bicaudal do tipo F\n",
    "            Entrada:\n",
    "               * F: Valor calculado de F_0;\n",
    "               * alpha: nivel de confian√ßa total;\n",
    "               * dn: graus de liberdade do numerador;\n",
    "               * dd: graus de liberdade do denominado.\n",
    "\n",
    "            Sa√≠das:\n",
    "               * Impress√£o das Respostas.\n",
    "\n",
    "            Retorno: Nenhum\n",
    "    '''\n",
    "    min = st.f.ppf(alpha/2, dn, dd)         # Limite Superior\n",
    "    max = st.f.ppf(1-(alpha/2), dn, dd)     # Limite Inferior\n",
    "\n",
    "    print('O valor da estat√≠sca c√°lcula F0 √©: {:.4f}'.format(F))\n",
    "    print('O limites da distribui√ß√£o para {} de {:.2f} √©: [{:.4f}:{:.4f}]'.format('\\u0251', alpha, min, max))\n",
    "    print('Portanto,',end=' ')\n",
    "\n",
    "    if (F<min) or (F>max):\n",
    "        print('\\033[33mREJEITA-SE\\033[m a hip√≥tese nula!')\n",
    "        print('p-valor: {}'.format( st.f.cdf(F, dn, dd) if (F<min) else (1-st.f.cdf(F, dn, dd)) ))\n",
    "    else:\n",
    "        print('\\033[31mFALHA EM REJEITAR\\033[m a hip√≥tese nula!')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "source": [
    "   * **Fun√ß√£o:** Calculo do erro padr√£o de uma regress√£o linear multipla"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_mult_regress_error (C0, var2):\n",
    "    '''\n",
    "    Fun√ß√£o de calculo de erro padr√£o de cada constantes:\n",
    "        Entradas:\n",
    "            * C0 = Matriz de covari√¢ncia da regress√£o\n",
    "            * var2 = variancia do erro padr√£o\n",
    "        Saida/Retorno:\n",
    "            * se = array com os erros padr√µes\n",
    "    '''\n",
    "    se = []\n",
    "\n",
    "    for i in range(len(C0)):\n",
    "        se.append(sqrt(var2*C0[i,i]))\n",
    "    \n",
    "    return se"
   ]
  },
  {
   "source": [
    "## *Importa√ß√£o dos dados*\n",
    "Todos os dados utilizados nessa an√°lise est√£o disponibilizados na plataforma Kaggle. Caso queria acessar a fonte dos dados utilizados basta [clicar aqui.](https://www.kaggle.com/afumetto/3dprinter?select=data.csv)  \n",
    "\n",
    "### Contexto  \n",
    "Os dados utilizados s√£o oriundos de uma pesquisa desenvolvida pelo Departamento de Engenharia Mec√¢nica da TR/Selcuk University.  \n",
    "Essa pesquisa visava avaliar quais os par√¢metros de impress√£o interferem na qualidade de impress√£o de pe√ßas, precis√£o e rigidez.  \n",
    "Nos dados apresentados existem nove par√¢metro de configura√ß√£o (entradas), e as medi√ß√µes de tr√™s par√¢metros de sa√≠da.  \n",
    "\n",
    "### Materiais e M√©todos  \n",
    "* **Impressora:** Ultimaker S5 3-D \n",
    "* **Teste de materiais e resist√™ncia:** Sincotec GMBH, capacidade de tra√ß√£o - 20kN.\n",
    "\n",
    "### Conte√∫do dos dados\n",
    "#### Entradas - Par√¢metros de configura√ß√£o:  \n",
    "* Altura de camada (*Layer Height*) \\[mm]  \n",
    "* Espessura de casca (*Wall Thickness*) \\[mm]  \n",
    "* Densidade de preenchimento (*Infill Density*) \\[%]  \n",
    "* Padr√£o de preenchimento (*Infill Pattern*)  \n",
    "* Temperatura do bico de extrus√£o (*Nozzle Temperature*) \\[¬∞C]  \n",
    "* Temperetura da mesa de impress√£o (*Bed Temperature*) \\[¬∞C]  \n",
    "* Velocidade de impress√£o (*Print Speed*) \\[mm/s]  \n",
    "* Material (*Material*)  \n",
    "* Velocidade do vetilador da extrusora (*Fan Speed*) \\[%]  \n",
    "\n",
    "#### Sa√≠das  \n",
    "* Rugosidade (*Roughness*) \\[¬µm]\n",
    "* Tens√£o de ruptura (*Ultimate Tension Strenght*) \\[MPa]\n",
    "* Alonga√ß√£o (*Elongation*) \\[%]  \n",
    "\n",
    "Abaixo importamos os dados para a an√°lise.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   layer_height  wall_thickness  infill_density infill_pattern  \\\n",
       "0          0.02               8              90           grid   \n",
       "1          0.02               7              90      honeycomb   \n",
       "2          0.02               1              80           grid   \n",
       "3          0.02               4              70      honeycomb   \n",
       "4          0.02               6              90           grid   \n",
       "\n",
       "   nozzle_temperature  bed_temperature  print_speed material  fan_speed  \\\n",
       "0                 220               60           40      abs          0   \n",
       "1                 225               65           40      abs         25   \n",
       "2                 230               70           40      abs         50   \n",
       "3                 240               75           40      abs         75   \n",
       "4                 250               80           40      abs        100   \n",
       "\n",
       "   roughness  tension_strenght  elongation  \n",
       "0         25                18         1.2  \n",
       "1         32                16         1.4  \n",
       "2         40                 8         0.8  \n",
       "3         68                10         0.5  \n",
       "4         92                 5         0.7  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>layer_height</th>\n      <th>wall_thickness</th>\n      <th>infill_density</th>\n      <th>infill_pattern</th>\n      <th>nozzle_temperature</th>\n      <th>bed_temperature</th>\n      <th>print_speed</th>\n      <th>material</th>\n      <th>fan_speed</th>\n      <th>roughness</th>\n      <th>tension_strenght</th>\n      <th>elongation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.02</td>\n      <td>8</td>\n      <td>90</td>\n      <td>grid</td>\n      <td>220</td>\n      <td>60</td>\n      <td>40</td>\n      <td>abs</td>\n      <td>0</td>\n      <td>25</td>\n      <td>18</td>\n      <td>1.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02</td>\n      <td>7</td>\n      <td>90</td>\n      <td>honeycomb</td>\n      <td>225</td>\n      <td>65</td>\n      <td>40</td>\n      <td>abs</td>\n      <td>25</td>\n      <td>32</td>\n      <td>16</td>\n      <td>1.4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.02</td>\n      <td>1</td>\n      <td>80</td>\n      <td>grid</td>\n      <td>230</td>\n      <td>70</td>\n      <td>40</td>\n      <td>abs</td>\n      <td>50</td>\n      <td>40</td>\n      <td>8</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.02</td>\n      <td>4</td>\n      <td>70</td>\n      <td>honeycomb</td>\n      <td>240</td>\n      <td>75</td>\n      <td>40</td>\n      <td>abs</td>\n      <td>75</td>\n      <td>68</td>\n      <td>10</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.02</td>\n      <td>6</td>\n      <td>90</td>\n      <td>grid</td>\n      <td>250</td>\n      <td>80</td>\n      <td>40</td>\n      <td>abs</td>\n      <td>100</td>\n      <td>92</td>\n      <td>5</td>\n      <td>0.7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "dados = pd.read_csv('datasets\\data_3D_print.csv')   # Importa o DataFrame\n",
    "dados.head()     # Apresenta as 5 primeiras linhas do DataFrame"
   ]
  },
  {
   "source": [
    "## *An√°lise das Sa√≠das*  \n",
    "Como temos tr√™s saidas iremos analisa-las separadamente.  \n",
    "\n",
    "### Saida Rugosidade:  \n",
    "\n",
    "#### ***Influ√™ncia do material***  \n",
    "Umas das primeiras hip√≥teses que desejamos saber do ponto de vista da rugosidade √© se o material afeta estatisticamente seu valor, para isso separaremos as sa√≠das de rugosidade por material para realizar uma an√°lise de experimento com um √∫nico fator."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  material  roughness\n",
       "0      abs         25\n",
       "1      abs         32\n",
       "2      abs         40\n",
       "3      abs         68\n",
       "4      abs         92"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>material</th>\n      <th>roughness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abs</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abs</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>abs</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>abs</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>abs</td>\n      <td>92</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "dados_roughness_material = dados[['material','roughness']]\n",
    "dados_roughness_material.head()"
   ]
  },
  {
   "source": [
    "Com os dados separados podemos observar que nosso problema √© dividido em dois materiais, ou seja, dois n√≠veis (PLA e ABS). Primeiramente vamos analisar quantas observa√ß√µes de cada materiais nos temos.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "abs    25\n",
       "pla    25\n",
       "Name: material, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "dados_roughness_material['material'].value_counts()"
   ]
  },
  {
   "source": [
    "Como podemos observa o n√∫mero de observa√ß√µes de cada material √© igual.\n",
    "***\n",
    "#### Teoria üìñ:  \n",
    "Supomos que nosso valor de sa√≠da rugosidade varia de acordo com o material utilizado, o que significaria que ela teria o seguinte comportamento:  \n",
    "$$\n",
    "\\mathsf{\n",
    "    Y_{ij}= \\mu + \\tau_{i} + \\epsilon_{ij}\n",
    "}\n",
    "\\left\\{\\displaystyle\n",
    "    \\begin{array}{l}\n",
    "        \\mathsf{i=0, 1}\\\\\n",
    "        \\mathsf{j=0, 1, 2, 3, \\dots, 25}\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$  \n",
    "Onde:\n",
    "   * $\\mu$: m√©dia global;  \n",
    "   * $\\tau_{i}$: fator de altera√ß√£o referente ao material utilizado;\n",
    "   * $\\epsilon_{ij}$: erro aleatorio da medi√ß√£o  \n",
    "***  \n",
    "Para garantirmos que o realmente o material interfere na rugosidade medida nas nossas pe√ßas temos que garantir que o valor de $\\tau$ de cada material seja diferente de zero. Logo temos que fazer um teste assumindo as seguintes hip√≥teses:  \n",
    "$$\n",
    "\\left\\{\n",
    "    \\begin{array}{}\n",
    "        \\mathsf{\\mathit{H_0}: \\tau_{0}=\\tau_{1}=0}\\\\\n",
    "        \\mathsf{\\mathit{H_1}: \\tau_{0}\\not=\\tau_{1}\\not=0}\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$  \n",
    "Para isso faremos um teste ANOVA. Para isso assumimos que o modelo assumi uma estat√≠stica F, assim:  \n",
    "$$\n",
    "\\mathsf{\n",
    "    F_0=\\dfrac{\\dfrac{SQ_{tratamentos}}{a-1}}{\\dfrac{SQ_{E}}{a\\cdot\\left(n-1\\right)}}=\n",
    "\\dfrac{\\dfrac{n \\cdot \\displaystyle\\sum_{i=1}^{a=2}\\left(\\bar{y}_{i\\cdot} - \\bar{y}_{\\cdot\\cdot}\\right)^2}{a-1}}{\\dfrac{\\displaystyle\\sum_{i=1}^{a=2} \\sum_{j=1}^{n=25}\\left(y_{ij}-\\bar{y}_{i\\cdot}\\right)^2}{a\\cdot\\left(n-1\\right)}}=\n",
    "    \\dfrac{MQ_{tratamentos}}{MQ_E}\n",
    "}\n",
    "$$  \n",
    "\n",
    "Para iniciarmos os calculos vamos primeiramente calular as m√©dia e armazena-las"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "mean_roug_mat = dados_roughness_material.groupby('material').mean()   # media da rugosidade por material\n",
    "mean_roug_mat"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          roughness\n",
       "material           \n",
       "abs          193.44\n",
       "pla          147.72"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>roughness</th>\n    </tr>\n    <tr>\n      <th>material</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>abs</th>\n      <td>193.44</td>\n    </tr>\n    <tr>\n      <th>pla</th>\n      <td>147.72</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "170.58"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "mean_roug_mat_gen = dados_roughness_material['roughness'].mean()  # M√©dia Geral \n",
    "mean_roug_mat_gen"
   ]
  },
  {
   "source": [
    "Calculando o $SQ_{tratamentos}$:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "26128.980000000003"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "n = (dados_roughness_material['material'].value_counts()).loc['abs']\n",
    "SQ_trat = n * sum((mean_roug_mat['roughness']-mean_roug_mat_gen)**2)\n",
    "SQ_trat"
   ]
  },
  {
   "source": [
    "Calculando $SQ_E$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "454451.19999999995"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "SQ_abs = sum((dados_roughness_material[dados_roughness_material['material']=='abs']['roughness']-float(mean_roug_mat.loc['abs']))**2)\n",
    "SQ_pla = sum((dados_roughness_material[dados_roughness_material['material']=='pla']['roughness']-float(mean_roug_mat.loc['pla']))**2)\n",
    "\n",
    "SQ_e = SQ_abs+SQ_pla\n",
    "SQ_e"
   ]
  },
  {
   "source": [
    "Com os erros quadr√°ticos calculados podemos fazer o teste de hip√≥tese:  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "O valor da estat√≠sca c√°lcula F0 √©: 2.7598\nO limites da distribui√ß√£o para …ë de 0.05 √©: [0.0010:5.3541]\nPortanto, \u001b[31mFALHA EM REJEITAR\u001b[m a hip√≥tese nula!\n"
     ]
    }
   ],
   "source": [
    "a = len(mean_roug_mat)\n",
    "\n",
    "MQ_trat = SQ_trat/(a-1)\n",
    "MQe = SQ_e/(a*(n-1))\n",
    "\n",
    "F0 = MQ_trat/MQe\n",
    "\n",
    "F_bicaudal_hypoteses(F0, 0.05, a-1, a*(n-1))"
   ]
  },
  {
   "source": [
    "Como podemos observar para um $\\alpha$ de 0,05 FALHAMOS EM REJEITAR a hip√≥tese nula, logo o material n√£o afeta estat√≠sticamente no valor de rugosidade.   \n",
    "Al√©m do teste ANOVA utilizaremos ent√£o o m√©todo MDS para avaliar se a as m√©dias medidas tem diferen√ßa significativas na rugosidade.  \n",
    "Para isso temos que para as m√©dias terem diferen√ßas significativas devemos relacionar:  \n",
    "$$\n",
    "\\mathsf{\n",
    "    |\\bar{y}_{i\\cdot}-\\bar{y}_{j\\cdot}|> MDS\n",
    "}\n",
    "$$  \n",
    "$$\n",
    "\\mathsf{\n",
    "    |\\bar{y}_{i\\cdot}-\\bar{y}_{j\\cdot}|> \\mathit{t}_{\\frac{\\alpha}{2};a \\cdot(n-1)} \\cdot \\sqrt{\\dfrac{2\\cdot MQ_E}{n}}\n",
    "}\n",
    "$$  \n",
    "Assim:  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " abs-pla  |   MDS    \n 45.7200  | 55.3352  \n"
     ]
    }
   ],
   "source": [
    "MDS = st.t.ppf(1-0.025,a*(n-1)) * sqrt((2*MQe)/n)\n",
    "\n",
    "print('{:^10}|{:^10}'.format('abs-pla','MDS'))\n",
    "print('{:^1}{:.4f}{:^2}|{:^1}{:.4f}{:^2}'.format('',float(mean_roug_mat.loc['abs'] - mean_roug_mat.loc['pla']),'','', MDS,''))"
   ]
  },
  {
   "source": [
    "Analisando a m√≠nima diferen√ßa significativa (MDS), vemos que realmente a mudan√ßa do material n√£o afeta estatistiamente o valor da rugosidade.  \n",
    "Essa conclus√£o era esperada, uma vez que como a impress√£o ocorre por camadas, a rugosidade deve ser afeta prinicpalmente por par√¢metros que determinam as caracteristicas dessas camadas que o material em si.  \n",
    "\n",
    "### ***Analise do preenchimento interno***  \n",
    "Com a influ√™ncia do material sendo descartada agora avaliaremos se o preenchimento interno da pe√ßa influencia na rugosidade da pe√ßa.  \n",
    "Primeiramente vamos separar os dados de preenchimento interno e rugosidade.   "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  infill_pattern  roughness\n",
       "0           grid         25\n",
       "1      honeycomb         32\n",
       "2           grid         40\n",
       "3      honeycomb         68\n",
       "4           grid         92"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>infill_pattern</th>\n      <th>roughness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>grid</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>honeycomb</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>grid</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>honeycomb</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>grid</td>\n      <td>92</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "pattern_roughness = dados[['infill_pattern','roughness']]\n",
    "pattern_roughness.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "honeycomb    25\n",
       "grid         25\n",
       "Name: infill_pattern, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "pattern_roughness['infill_pattern'].value_counts()"
   ]
  },
  {
   "source": [
    "Separado os dados vamos ent√£o realizar um teste ANOVA seguindo as hip√≥teses:  \n",
    "$$\n",
    "\\left\\{\n",
    "    \\begin{array}{}\n",
    "        \\mathsf{\\mathit{H_0}: \\tau_{0}=\\tau_{1}=0}\\\\\n",
    "        \\mathsf{\\mathit{H_1}: \\tau_{0}\\not=\\tau_{1}\\not=0}\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$  \n",
    "Para isso assumimos que o modelo assumi uma estat√≠stica F, assim:  \n",
    "$$\n",
    "\\mathsf{\n",
    "    F_0~=~\\dfrac{\\dfrac{SQ_{tratamentos}}{a-1}}{\\dfrac{SQ_{E}}{a\\cdot\\left(n-1\\right)}}=\n",
    "\\dfrac{\\dfrac{n \\cdot \\displaystyle\\sum_{i=1}^{a=2}\\left(\\bar{y}_{i\\cdot} - \\bar{y}_{\\cdot\\cdot}\\right)^2}{a-1}}{\\dfrac{\\displaystyle\\sum_{i=1}^{a=2} \\sum_{j=1}^{n=25}\\left(y_{ij}-\\bar{y}_{i\\cdot}\\right)^2}{a\\cdot\\left(n-1\\right)}}=\n",
    "    \\dfrac{MQ_{tratamentos}}{MQ_E}\n",
    "}\n",
    "$$  \n",
    "Assim calculamos $F_0$ e fazemos o teste de hip√≥tese:  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                roughness\n",
       "infill_pattern           \n",
       "grid               177.28\n",
       "honeycomb          163.88"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>roughness</th>\n    </tr>\n    <tr>\n      <th>infill_pattern</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>grid</th>\n      <td>177.28</td>\n    </tr>\n    <tr>\n      <th>honeycomb</th>\n      <td>163.88</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "patt_rough_mean = pattern_roughness.groupby('infill_pattern').mean()\n",
    "patt_rough_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "roughness    170.58\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "patt_rough_gen = pattern_roughness.mean()\n",
    "patt_rough_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2244.500000000002"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "n_ptt = (pattern_roughness['infill_pattern'].value_counts()).loc['grid']\n",
    "SQ_tra_ptt = n_ptt * sum( (patt_rough_mean['roughness'] - float(patt_rough_gen))**2 )\n",
    "SQ_tra_ptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "478335.67999999993"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "SQ_e_grid = sum((pattern_roughness[pattern_roughness['infill_pattern']=='grid']['roughness'] - float(patt_rough_mean.loc['grid']))**2)\n",
    "SQ_e_hone = sum((pattern_roughness[pattern_roughness['infill_pattern']=='honeycomb']['roughness'] - float(patt_rough_mean.loc['honeycomb']))**2)\n",
    "\n",
    "SQ_e_ptt = SQ_e_grid + SQ_e_hone\n",
    "SQ_e_ptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "O valor da estat√≠sca c√°lcula F0 √©: 2.7598\nO limites da distribui√ß√£o para …ë de 0.05 √©: [0.0010:5.3541]\nPortanto, \u001b[31mFALHA EM REJEITAR\u001b[m a hip√≥tese nula!\n"
     ]
    }
   ],
   "source": [
    "a_ptt = len(patt_rough_mean)\n",
    "\n",
    "MQ_trat_ptt = SQ_tra_ptt/(a-1)\n",
    "MQe_ptt = SQ_e_ptt/(a*(n-1))\n",
    "\n",
    "F0_ptt = MQ_trat_ptt/MQe_ptt\n",
    "\n",
    "F_bicaudal_hypoteses(F0, 0.05, a-1, a*(n-1))"
   ]
  },
  {
   "source": [
    "#### ***Modelo de Regress√£o Linear Multipla***  \n",
    "Com os dados restantes vamos fazer um modelo de regress√£o multipla com 7 vari√°veis $\\mathsf{\\left(x_1, x_2, x_3, x_4, x_5, x_6, x_7\\right)}$, sendo cada uma dessas uma entrada medida restante, e possui 8 coeficientes $\\mathsf{\\left(\\hat{\\beta}_0, \\hat{\\beta}_1, \\hat{\\beta}_2, \\hat{\\beta}_3, \\hat{\\beta}_4, \\hat{\\beta}_5, \\hat{\\beta}_6, \\hat{\\beta}_7\\right)}$.  \n",
    "Primeiramente vamos separar os dados com rela√ß√£o com a rugosidade:  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   layer_height  wall_thickness  infill_density  nozzle_temperature  \\\n",
       "0          0.02               8              90                 220   \n",
       "1          0.02               7              90                 225   \n",
       "2          0.02               1              80                 230   \n",
       "3          0.02               4              70                 240   \n",
       "4          0.02               6              90                 250   \n",
       "\n",
       "   bed_temperature  print_speed  fan_speed  roughness  \n",
       "0               60           40          0         25  \n",
       "1               65           40         25         32  \n",
       "2               70           40         50         40  \n",
       "3               75           40         75         68  \n",
       "4               80           40        100         92  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>layer_height</th>\n      <th>wall_thickness</th>\n      <th>infill_density</th>\n      <th>nozzle_temperature</th>\n      <th>bed_temperature</th>\n      <th>print_speed</th>\n      <th>fan_speed</th>\n      <th>roughness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.02</td>\n      <td>8</td>\n      <td>90</td>\n      <td>220</td>\n      <td>60</td>\n      <td>40</td>\n      <td>0</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02</td>\n      <td>7</td>\n      <td>90</td>\n      <td>225</td>\n      <td>65</td>\n      <td>40</td>\n      <td>25</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.02</td>\n      <td>1</td>\n      <td>80</td>\n      <td>230</td>\n      <td>70</td>\n      <td>40</td>\n      <td>50</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.02</td>\n      <td>4</td>\n      <td>70</td>\n      <td>240</td>\n      <td>75</td>\n      <td>40</td>\n      <td>75</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.02</td>\n      <td>6</td>\n      <td>90</td>\n      <td>250</td>\n      <td>80</td>\n      <td>40</td>\n      <td>100</td>\n      <td>92</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "data_roughness = dados.drop(['infill_pattern', 'material', 'tension_strenght', 'elongation'], axis=1)\n",
    "data_roughness.head()"
   ]
  },
  {
   "source": [
    "***\n",
    "#### Teoria üìñ  \n",
    "Para determinarmos os coeficiente usaremos a seguinte rela√ß√£o: \n",
    "$$\n",
    "\\mathsf{\n",
    "    \\hat{\\beta} = \\left( X' \\cdot X \\right)^{-1} \\cdot X' \\cdot y\n",
    "}\n",
    "$$  \n",
    "Onde:  \n",
    "$$\n",
    "\\mathsf{y} = \\left[\n",
    "    \\begin{array}{c}\n",
    "        \\mathsf{y_1}\\\\ \\mathsf{y_2}\\\\ \\vdots \\\\ \\mathsf{y_n}\n",
    "    \\end{array}\n",
    "\\right];\n",
    "\n",
    "\\mathsf{X} = \\left[\n",
    "    \\begin{array}{ccccc}\n",
    "        1 & \\mathsf{x_{11}} & \\mathsf{x_{12}} & \\cdots & \\mathsf{x_{1k}}\\\\\n",
    "        1 & \\mathsf{x_{21}} & \\mathsf{x_{22}} & \\cdots & \\mathsf{x_{2k}}\\\\\n",
    "        \\vdots & \\vdots & \\vdots & \\vdots & \\vdots\\\\\n",
    "        1 & \\mathsf{x_{n1}} & \\mathsf{x_{n2}} & \\cdots & \\mathsf{x_{nk}}\n",
    "    \\end{array}\n",
    "\\right]; \n",
    "\n",
    "\\mathsf{\\hat{\\beta}} = \\left[\n",
    "    \\begin{array}{c}\n",
    "        \\mathsf{\\beta_0}\\\\ \\mathsf{\\beta_1}\\\\ \\vdots \\\\ \\mathsf{\\beta_0}\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$  \n",
    "\n",
    "Desta equa√ß√£o temos a matriz de covari√¢ncia que √©:  \n",
    "$$\n",
    "\\mathsf{\n",
    "    C = \\left(X' \\cdot X \\right)^{-1}\n",
    "}\n",
    "$$  \n",
    "***\n",
    "Primeiramente vamos determinar a matriz de covari√¢ncia:  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-1.37564362e+14,  1.15720408e+00,  7.06375086e-03,\n",
       "        -1.03045304e-04,  5.03537288e-04,  2.29273937e+12,\n",
       "         4.17333108e-04, -4.58547874e+11],\n",
       "       [ 3.34108686e-01,  5.24386052e+00,  3.13062506e-02,\n",
       "        -3.77559096e-04,  1.21916643e-03, -2.42494531e-02,\n",
       "         1.89362315e-03,  4.32886846e-03],\n",
       "       [-3.00018789e-02,  3.13062506e-02,  3.18852006e-03,\n",
       "        -4.09108343e-05,  1.25746058e-04, -3.81390035e-04,\n",
       "         1.32146819e-04,  5.20826542e-05],\n",
       "       [ 7.91752581e-04, -3.77559096e-04, -4.09108343e-05,\n",
       "         3.57060981e-05, -2.41652827e-05,  4.25007700e-05,\n",
       "         1.14141170e-06, -2.56327763e-06],\n",
       "       [-1.45193277e-02,  1.21916643e-03,  1.25746058e-04,\n",
       "        -2.41652827e-05,  1.65267613e-04, -3.30446443e-04,\n",
       "         3.39295021e-06,  2.54605757e-05],\n",
       "       [ 2.29273937e+12, -3.72677448e-02, -9.99376576e-04,\n",
       "         5.72053087e-05, -5.79531780e-04, -3.82123228e+10,\n",
       "        -6.57502051e-05,  7.64246457e+09],\n",
       "       [-2.62781756e-03,  1.89362315e-03,  1.32146819e-04,\n",
       "         1.14141170e-06,  3.39295021e-06, -1.49976941e-05,\n",
       "         2.89252055e-05,  2.46845363e-06],\n",
       "       [-4.58547874e+11,  7.22389236e-03,  1.76091249e-04,\n",
       "        -5.49792707e-06,  7.48912431e-05,  7.64246457e+09,\n",
       "         1.26189558e-05, -1.52849291e+09]])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "n = len(data_roughness)\n",
    "X_roug = np.array(pd.concat([pd.Series(np.ones(len(data_roughness))),data_roughness.iloc[:,:7]],axis=1))\n",
    "Y_roug = np.array(data_roughness['roughness'])\n",
    "\n",
    "C = np.linalg.inv((X_roug.T).dot(X_roug))\n",
    "C"
   ]
  },
  {
   "source": [
    "Com a matriz de covari√¢ncia podemos calcular os coeficientes da regress√£o:  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Œ≤0: 372.4155\nŒ≤1: 770.6541\nŒ≤2: 1.5708\nŒ≤3: 0.2734\nŒ≤4: 1.8998\nŒ≤5: -13.1164\nŒ≤6: 0.6373\nŒ≤7: 3.1169\n"
     ]
    }
   ],
   "source": [
    "B_rough = (C.dot(X_roug.T)).dot(Y_roug)\n",
    "\n",
    "for i in range(len(B_rough)):\n",
    "    print('{}{}: {:.4f}'.format('\\u03B2', i, B_rough[i]))"
   ]
  },
  {
   "source": [
    "Assim o modelo de multiplas vari√°veis dado √©:  \n",
    "$$\n",
    "\\mathsf{\n",
    "    \\hat{y}_{rugosidade} = 372,4155 + 770,6541 \\cdot x_1 + 1,5708 \\cdot x_2 + 0,2734 \\cdot x_3 - 1,8998 \\cdot x_4 -13,1164 \\cdot x_5 + 0,6373 \\cdot x_6 + 3,1169 \\cdot x_7\n",
    "}\n",
    "$$  \n",
    "\n",
    "#### Teste para signific√¢ncia  da Regress√£o  \n",
    "Para avliar se a nossa regress√£o √© significativa assumimos as hipoteses:  \n",
    "$$\n",
    "\\left\\{\n",
    "    \\begin{array}{l}\n",
    "        \\mathsf{\\mathit{H_0:} \\hat{\\beta}_i= 0}\\\\\n",
    "        \\mathsf{\\mathit{H_1: } \\hat{\\beta}_j \\not= 0}\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$  \n",
    "Com a estat√≠stica:  \n",
    "$$\n",
    "\\mathsf{\n",
    "    F_0 = \\dfrac{\\dfrac{SQ_R}{k}}{\\dfrac{SQ_E}{n-p}} \n",
    "}\n",
    "$$  \n",
    "Onde:\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "    \\mathsf{SQ_R = \\displaystyle\\sum_{i=1}^{n=50} \\left(\\hat{y}_i - \\bar{y}\\right)^2} & \\mathsf{e} & \\mathsf{k = p-1}\n",
    "\\end{array}\n",
    "$$  \n",
    "$$\n",
    "\\mathsf{\n",
    "    SQ_E = \\sum_{i=1}^{n=50}{\\left(y_i - \\hat{y}\\right)^2}\n",
    "}\n",
    "$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "O valor da estat√≠sca c√°lcula F0 √©: 9.5380\n",
      "O limites da distribui√ß√£o para …ë de 0.05 √©: [0.1999:2.7195]\n",
      "Portanto, \u001b[33mREJEITA-SE\u001b[m a hip√≥tese nula!\n",
      "p-valor: 1.1553901703154068e-06\n"
     ]
    }
   ],
   "source": [
    "Y_hat_roug = B_rough[0] + B_rough[1]*data_roughness['layer_height'] + B_rough[2]*data_roughness['wall_thickness'] + B_rough[3]*data_roughness['infill_density'] + B_rough[4]*data_roughness['nozzle_temperature'] + B_rough[5]*data_roughness['bed_temperature'] + B_rough[6]*data_roughness['print_speed'] + B_rough[7]*data_roughness['fan_speed']\n",
    "\n",
    "SQe_roug = sum( (Y_roug-Y_hat_roug)**2 )\n",
    "\n",
    "n_roug = len(Y_roug)\n",
    "p_roug = len(B_rough)-1\n",
    "k_roug =  p_roug-1\n",
    "\n",
    "SQr_roug = sum( (Y_hat_roug - data_roughness['roughness'].mean())**2 )\n",
    "\n",
    "F0_roug = (SQr_roug/k_roug)/(SQe_roug/(n_roug-p_roug))\n",
    "\n",
    "F_bicaudal_hypoteses(F0_roug, 0.05, k_roug, n_roug-p_roug)"
   ]
  },
  {
   "source": [
    "Como podemos ver falhamos em rejeitar a hip√¥tese nula, logo ao menos uma constate tem influ√™ncia estat√≠stica no valor de rugosidade.\n",
    "\n",
    "Agora basta determinarmos quais das vari√°veis interferem realmente na rugosidade. Para isso consideraremos as seguintes hip√≥teses para o teste de hip√≥teses dos coeficientes:  \n",
    "$$\n",
    "\\left\\{\n",
    "    \\begin{array}{}\n",
    "        \\mathsf{\\mathit{H_0:~}\\hat{\\beta}_j = 0}\\\\\n",
    "        \\mathsf{\\mathit{H_1:~}\\hat{\\beta}_j \\not=0}\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$  \n",
    "Porem agora utilizaremos a seguinte estat√≠stica:  \n",
    "$$\n",
    "\\mathsf{\n",
    "    T_0 = \\dfrac{\\hat{\\beta}j - \\beta_{j_0}}{\\sqrt{\\sigma^2 \\cdot C_{jj}}} = \\dfrac{\\hat{\\beta}j - \\beta_{j_0}}{se(\\hat{\\beta}_j)}\n",
    "}\n",
    "$$ \n",
    "\n",
    "Onde: \n",
    "$$\n",
    "\\mathsf{\n",
    "    \\hat{\\sigma}^2 = \\dfrac{SQ_E}{n-p} = \\dfrac{\\displaystyle \\sum_{i=1}^{n=50}{\\left(y_i - \\hat{y}\\right)^2}}{50-7}\n",
    "}\n",
    "$$  \n",
    "Primeiramente calcularemos a vari√¢ncia do erro e os erro padr√£o de cada coeficiente.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "math domain error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-f8720244b802>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSQe_roug\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_roug\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mp_roug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mseB_roug\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlin_mult_regress_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mseB_roug\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-61853f1e99f5>\u001b[0m in \u001b[0;36mlin_mult_regress_error\u001b[1;34m(C0, var2)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mC0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "var = SQe_roug/(n_roug-p_roug)\n",
    "\n",
    "seB_roug = lin_mult_regress_error(C, var)\n",
    "seB_roug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[-5.18399490577233e+17,\n",
       " 19761.03825045516,\n",
       " 12.015664150058617,\n",
       " 0.13455536565422027,\n",
       " 0.6227968145232046,\n",
       " -143999858493670.97,\n",
       " 0.10900215410839553,\n",
       " -5759994339746.895]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "se = []\n",
    "\n",
    "for i in range(len(C)):\n",
    "    se.append(float(var*C[i,i]))\n",
    "\n",
    "se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      0  layer_height  wall_thickness  infill_density  nozzle_temperature  \\\n",
       "0   1.0          0.02               8              90                 220   \n",
       "1   1.0          0.02               7              90                 225   \n",
       "2   1.0          0.02               1              80                 230   \n",
       "3   1.0          0.02               4              70                 240   \n",
       "4   1.0          0.02               6              90                 250   \n",
       "5   1.0          0.02              10              40                 200   \n",
       "6   1.0          0.02               5              10                 205   \n",
       "7   1.0          0.02              10              10                 210   \n",
       "8   1.0          0.02               9              70                 215   \n",
       "9   1.0          0.02               8              40                 220   \n",
       "10  1.0          0.06               6              80                 220   \n",
       "11  1.0          0.06               2              20                 225   \n",
       "12  1.0          0.06              10              50                 230   \n",
       "13  1.0          0.06               6              10                 240   \n",
       "14  1.0          0.06               3              50                 250   \n",
       "15  1.0          0.06              10              90                 200   \n",
       "16  1.0          0.06               3              40                 205   \n",
       "17  1.0          0.06               8              30                 210   \n",
       "18  1.0          0.06               5              80                 215   \n",
       "19  1.0          0.06              10              50                 220   \n",
       "20  1.0          0.10               1              40                 220   \n",
       "21  1.0          0.10               2              30                 225   \n",
       "22  1.0          0.10               1              50                 230   \n",
       "23  1.0          0.10               9              80                 240   \n",
       "24  1.0          0.10               2              60                 250   \n",
       "25  1.0          0.10               1              50                 200   \n",
       "26  1.0          0.10               4              40                 205   \n",
       "27  1.0          0.10               3              50                 210   \n",
       "28  1.0          0.10               4              90                 215   \n",
       "29  1.0          0.10               1              30                 220   \n",
       "30  1.0          0.15               4              50                 220   \n",
       "31  1.0          0.15               7              10                 225   \n",
       "32  1.0          0.15               6              50                 230   \n",
       "33  1.0          0.15               1              50                 240   \n",
       "34  1.0          0.15               7              80                 250   \n",
       "35  1.0          0.15               3              80                 200   \n",
       "36  1.0          0.15               4              50                 205   \n",
       "37  1.0          0.15              10              30                 210   \n",
       "38  1.0          0.15               6              40                 215   \n",
       "39  1.0          0.15               1              10                 220   \n",
       "40  1.0          0.20               4              80                 220   \n",
       "41  1.0          0.20               9              90                 225   \n",
       "42  1.0          0.20               7              30                 230   \n",
       "43  1.0          0.20               6              90                 240   \n",
       "44  1.0          0.20               3              80                 250   \n",
       "45  1.0          0.20               5              60                 200   \n",
       "46  1.0          0.20               4              20                 205   \n",
       "47  1.0          0.20               5              60                 210   \n",
       "48  1.0          0.20               7              40                 215   \n",
       "49  1.0          0.20               3              60                 220   \n",
       "\n",
       "    bed_temperature  print_speed  fan_speed  \n",
       "0                60           40          0  \n",
       "1                65           40         25  \n",
       "2                70           40         50  \n",
       "3                75           40         75  \n",
       "4                80           40        100  \n",
       "5                60           40          0  \n",
       "6                65           40         25  \n",
       "7                70           40         50  \n",
       "8                75           40         75  \n",
       "9                80           40        100  \n",
       "10               60           60          0  \n",
       "11               65           60         25  \n",
       "12               70           60         50  \n",
       "13               75           60         75  \n",
       "14               80           60        100  \n",
       "15               60           60          0  \n",
       "16               65           60         25  \n",
       "17               70           60         50  \n",
       "18               75           60         75  \n",
       "19               80           60        100  \n",
       "20               60          120          0  \n",
       "21               65          120         25  \n",
       "22               70          120         50  \n",
       "23               75          120         75  \n",
       "24               80          120        100  \n",
       "25               60          120          0  \n",
       "26               65          120         25  \n",
       "27               70          120         50  \n",
       "28               75          120         75  \n",
       "29               80          120        100  \n",
       "30               60           60          0  \n",
       "31               65           60         25  \n",
       "32               70           60         50  \n",
       "33               75           60         75  \n",
       "34               80           60        100  \n",
       "35               60           60          0  \n",
       "36               65           60         25  \n",
       "37               70           60         50  \n",
       "38               75           60         75  \n",
       "39               80           60        100  \n",
       "40               60           40          0  \n",
       "41               65           40         25  \n",
       "42               70           40         50  \n",
       "43               75           40         75  \n",
       "44               80           40        100  \n",
       "45               60           40          0  \n",
       "46               65           40         25  \n",
       "47               70           40         50  \n",
       "48               75           40         75  \n",
       "49               80           40        100  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>layer_height</th>\n      <th>wall_thickness</th>\n      <th>infill_density</th>\n      <th>nozzle_temperature</th>\n      <th>bed_temperature</th>\n      <th>print_speed</th>\n      <th>fan_speed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.02</td>\n      <td>8</td>\n      <td>90</td>\n      <td>220</td>\n      <td>60</td>\n      <td>40</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.02</td>\n      <td>7</td>\n      <td>90</td>\n      <td>225</td>\n      <td>65</td>\n      <td>40</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.02</td>\n      <td>1</td>\n      <td>80</td>\n      <td>230</td>\n      <td>70</td>\n      <td>40</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.02</td>\n      <td>4</td>\n      <td>70</td>\n      <td>240</td>\n      <td>75</td>\n      <td>40</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.02</td>\n      <td>6</td>\n      <td>90</td>\n      <td>250</td>\n      <td>80</td>\n      <td>40</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.0</td>\n      <td>0.02</td>\n      <td>10</td>\n      <td>40</td>\n      <td>200</td>\n      <td>60</td>\n      <td>40</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.0</td>\n      <td>0.02</td>\n      <td>5</td>\n      <td>10</td>\n      <td>205</td>\n      <td>65</td>\n      <td>40</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.0</td>\n      <td>0.02</td>\n      <td>10</td>\n      <td>10</td>\n      <td>210</td>\n      <td>70</td>\n      <td>40</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.0</td>\n      <td>0.02</td>\n      <td>9</td>\n      <td>70</td>\n      <td>215</td>\n      <td>75</td>\n      <td>40</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.0</td>\n      <td>0.02</td>\n      <td>8</td>\n      <td>40</td>\n      <td>220</td>\n      <td>80</td>\n      <td>40</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.0</td>\n      <td>0.06</td>\n      <td>6</td>\n      <td>80</td>\n      <td>220</td>\n      <td>60</td>\n      <td>60</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.0</td>\n      <td>0.06</td>\n      <td>2</td>\n      <td>20</td>\n      <td>225</td>\n      <td>65</td>\n      <td>60</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.0</td>\n      <td>0.06</td>\n      <td>10</td>\n      <td>50</td>\n      <td>230</td>\n      <td>70</td>\n      <td>60</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1.0</td>\n      <td>0.06</td>\n      <td>6</td>\n      <td>10</td>\n      <td>240</td>\n      <td>75</td>\n      <td>60</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1.0</td>\n      <td>0.06</td>\n      <td>3</td>\n      <td>50</td>\n      <td>250</td>\n      <td>80</td>\n      <td>60</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1.0</td>\n      <td>0.06</td>\n      <td>10</td>\n      <td>90</td>\n      <td>200</td>\n      <td>60</td>\n      <td>60</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1.0</td>\n      <td>0.06</td>\n      <td>3</td>\n      <td>40</td>\n      <td>205</td>\n      <td>65</td>\n      <td>60</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1.0</td>\n      <td>0.06</td>\n      <td>8</td>\n      <td>30</td>\n      <td>210</td>\n      <td>70</td>\n      <td>60</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1.0</td>\n      <td>0.06</td>\n      <td>5</td>\n      <td>80</td>\n      <td>215</td>\n      <td>75</td>\n      <td>60</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1.0</td>\n      <td>0.06</td>\n      <td>10</td>\n      <td>50</td>\n      <td>220</td>\n      <td>80</td>\n      <td>60</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1.0</td>\n      <td>0.10</td>\n      <td>1</td>\n      <td>40</td>\n      <td>220</td>\n      <td>60</td>\n      <td>120</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>1.0</td>\n      <td>0.10</td>\n      <td>2</td>\n      <td>30</td>\n      <td>225</td>\n      <td>65</td>\n      <td>120</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1.0</td>\n      <td>0.10</td>\n      <td>1</td>\n      <td>50</td>\n      <td>230</td>\n      <td>70</td>\n      <td>120</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>1.0</td>\n      <td>0.10</td>\n      <td>9</td>\n      <td>80</td>\n      <td>240</td>\n      <td>75</td>\n      <td>120</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>1.0</td>\n      <td>0.10</td>\n      <td>2</td>\n      <td>60</td>\n      <td>250</td>\n      <td>80</td>\n      <td>120</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>1.0</td>\n      <td>0.10</td>\n      <td>1</td>\n      <td>50</td>\n      <td>200</td>\n      <td>60</td>\n      <td>120</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>1.0</td>\n      <td>0.10</td>\n      <td>4</td>\n      <td>40</td>\n      <td>205</td>\n      <td>65</td>\n      <td>120</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>1.0</td>\n      <td>0.10</td>\n      <td>3</td>\n      <td>50</td>\n      <td>210</td>\n      <td>70</td>\n      <td>120</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>1.0</td>\n      <td>0.10</td>\n      <td>4</td>\n      <td>90</td>\n      <td>215</td>\n      <td>75</td>\n      <td>120</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>1.0</td>\n      <td>0.10</td>\n      <td>1</td>\n      <td>30</td>\n      <td>220</td>\n      <td>80</td>\n      <td>120</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>1.0</td>\n      <td>0.15</td>\n      <td>4</td>\n      <td>50</td>\n      <td>220</td>\n      <td>60</td>\n      <td>60</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>1.0</td>\n      <td>0.15</td>\n      <td>7</td>\n      <td>10</td>\n      <td>225</td>\n      <td>65</td>\n      <td>60</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>1.0</td>\n      <td>0.15</td>\n      <td>6</td>\n      <td>50</td>\n      <td>230</td>\n      <td>70</td>\n      <td>60</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>1.0</td>\n      <td>0.15</td>\n      <td>1</td>\n      <td>50</td>\n      <td>240</td>\n      <td>75</td>\n      <td>60</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>1.0</td>\n      <td>0.15</td>\n      <td>7</td>\n      <td>80</td>\n      <td>250</td>\n      <td>80</td>\n      <td>60</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>1.0</td>\n      <td>0.15</td>\n      <td>3</td>\n      <td>80</td>\n      <td>200</td>\n      <td>60</td>\n      <td>60</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>1.0</td>\n      <td>0.15</td>\n      <td>4</td>\n      <td>50</td>\n      <td>205</td>\n      <td>65</td>\n      <td>60</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>1.0</td>\n      <td>0.15</td>\n      <td>10</td>\n      <td>30</td>\n      <td>210</td>\n      <td>70</td>\n      <td>60</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>1.0</td>\n      <td>0.15</td>\n      <td>6</td>\n      <td>40</td>\n      <td>215</td>\n      <td>75</td>\n      <td>60</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>1.0</td>\n      <td>0.15</td>\n      <td>1</td>\n      <td>10</td>\n      <td>220</td>\n      <td>80</td>\n      <td>60</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>1.0</td>\n      <td>0.20</td>\n      <td>4</td>\n      <td>80</td>\n      <td>220</td>\n      <td>60</td>\n      <td>40</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>1.0</td>\n      <td>0.20</td>\n      <td>9</td>\n      <td>90</td>\n      <td>225</td>\n      <td>65</td>\n      <td>40</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>1.0</td>\n      <td>0.20</td>\n      <td>7</td>\n      <td>30</td>\n      <td>230</td>\n      <td>70</td>\n      <td>40</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>1.0</td>\n      <td>0.20</td>\n      <td>6</td>\n      <td>90</td>\n      <td>240</td>\n      <td>75</td>\n      <td>40</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>1.0</td>\n      <td>0.20</td>\n      <td>3</td>\n      <td>80</td>\n      <td>250</td>\n      <td>80</td>\n      <td>40</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>1.0</td>\n      <td>0.20</td>\n      <td>5</td>\n      <td>60</td>\n      <td>200</td>\n      <td>60</td>\n      <td>40</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>1.0</td>\n      <td>0.20</td>\n      <td>4</td>\n      <td>20</td>\n      <td>205</td>\n      <td>65</td>\n      <td>40</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>1.0</td>\n      <td>0.20</td>\n      <td>5</td>\n      <td>60</td>\n      <td>210</td>\n      <td>70</td>\n      <td>40</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>1.0</td>\n      <td>0.20</td>\n      <td>7</td>\n      <td>40</td>\n      <td>215</td>\n      <td>75</td>\n      <td>40</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>1.0</td>\n      <td>0.20</td>\n      <td>3</td>\n      <td>60</td>\n      <td>220</td>\n      <td>80</td>\n      <td>40</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "X = pd.concat([pd.Series(np.ones(len(data_roughness))),data_roughness.iloc[:,:7]],axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                          0  layer_height  wall_thickness  infill_density  \\\n",
       "0                      50.0         5.300          261.00          2670.0   \n",
       "layer_height            5.3         0.765           25.89           283.3   \n",
       "wall_thickness        261.0        25.890         1781.00         14310.0   \n",
       "infill_density       2670.0       283.300        14310.00        174100.0   \n",
       "nozzle_temperature  11075.0      1173.950        57560.00        595800.0   \n",
       "bed_temperature      3500.0       371.000        18240.00        186900.0   \n",
       "print_speed          3200.0       334.000        14920.00        167400.0   \n",
       "fan_speed            2500.0       265.000        12900.00        133500.0   \n",
       "\n",
       "                    nozzle_temperature  bed_temperature  print_speed  \\\n",
       "0                             11075.00           3500.0       3200.0   \n",
       "layer_height                   1173.95            371.0        334.0   \n",
       "wall_thickness                57560.00          18240.0      14920.0   \n",
       "infill_density               595800.00         186900.0     167400.0   \n",
       "nozzle_temperature          2463875.00         778375.0     708800.0   \n",
       "bed_temperature              778375.00         247500.0     224000.0   \n",
       "print_speed                  708800.00         224000.0     248000.0   \n",
       "fan_speed                    569375.00         187500.0     160000.0   \n",
       "\n",
       "                    fan_speed  \n",
       "0                      2500.0  \n",
       "layer_height            265.0  \n",
       "wall_thickness        12900.0  \n",
       "infill_density       133500.0  \n",
       "nozzle_temperature   569375.0  \n",
       "bed_temperature      187500.0  \n",
       "print_speed          160000.0  \n",
       "fan_speed            187500.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>layer_height</th>\n      <th>wall_thickness</th>\n      <th>infill_density</th>\n      <th>nozzle_temperature</th>\n      <th>bed_temperature</th>\n      <th>print_speed</th>\n      <th>fan_speed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50.0</td>\n      <td>5.300</td>\n      <td>261.00</td>\n      <td>2670.0</td>\n      <td>11075.00</td>\n      <td>3500.0</td>\n      <td>3200.0</td>\n      <td>2500.0</td>\n    </tr>\n    <tr>\n      <th>layer_height</th>\n      <td>5.3</td>\n      <td>0.765</td>\n      <td>25.89</td>\n      <td>283.3</td>\n      <td>1173.95</td>\n      <td>371.0</td>\n      <td>334.0</td>\n      <td>265.0</td>\n    </tr>\n    <tr>\n      <th>wall_thickness</th>\n      <td>261.0</td>\n      <td>25.890</td>\n      <td>1781.00</td>\n      <td>14310.0</td>\n      <td>57560.00</td>\n      <td>18240.0</td>\n      <td>14920.0</td>\n      <td>12900.0</td>\n    </tr>\n    <tr>\n      <th>infill_density</th>\n      <td>2670.0</td>\n      <td>283.300</td>\n      <td>14310.00</td>\n      <td>174100.0</td>\n      <td>595800.00</td>\n      <td>186900.0</td>\n      <td>167400.0</td>\n      <td>133500.0</td>\n    </tr>\n    <tr>\n      <th>nozzle_temperature</th>\n      <td>11075.0</td>\n      <td>1173.950</td>\n      <td>57560.00</td>\n      <td>595800.0</td>\n      <td>2463875.00</td>\n      <td>778375.0</td>\n      <td>708800.0</td>\n      <td>569375.0</td>\n    </tr>\n    <tr>\n      <th>bed_temperature</th>\n      <td>3500.0</td>\n      <td>371.000</td>\n      <td>18240.00</td>\n      <td>186900.0</td>\n      <td>778375.00</td>\n      <td>247500.0</td>\n      <td>224000.0</td>\n      <td>187500.0</td>\n    </tr>\n    <tr>\n      <th>print_speed</th>\n      <td>3200.0</td>\n      <td>334.000</td>\n      <td>14920.00</td>\n      <td>167400.0</td>\n      <td>708800.00</td>\n      <td>224000.0</td>\n      <td>248000.0</td>\n      <td>160000.0</td>\n    </tr>\n    <tr>\n      <th>fan_speed</th>\n      <td>2500.0</td>\n      <td>265.000</td>\n      <td>12900.00</td>\n      <td>133500.0</td>\n      <td>569375.00</td>\n      <td>187500.0</td>\n      <td>160000.0</td>\n      <td>187500.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "A = X.T @ X\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-1.37683989e+14,  1.15976792e+00,  7.14111328e-03,\n",
       "        -1.06811523e-04,  4.88281250e-04,  2.29473314e+12,\n",
       "         4.39542826e-04, -4.58946629e+11],\n",
       "       [ 3.39268857e-01,  5.24386052e+00,  3.13062506e-02,\n",
       "        -3.77559096e-04,  1.21916643e-03, -2.36354910e-02,\n",
       "         1.89362315e-03,  4.49744160e-03],\n",
       "       [-3.04713938e-02,  3.13062506e-02,  3.18852006e-03,\n",
       "        -4.09108343e-05,  1.25746058e-04, -3.73790832e-04,\n",
       "         1.32146819e-04,  5.09741000e-05],\n",
       "       [ 7.86330292e-04, -3.77559096e-04, -4.09108343e-05,\n",
       "         3.57060981e-05, -2.41652827e-05,  4.23823821e-05,\n",
       "         1.14141170e-06, -2.53334175e-06],\n",
       "       [-1.47605066e-02,  1.21916643e-03,  1.25746058e-04,\n",
       "        -2.41652827e-05,  1.65267613e-04, -3.25131048e-04,\n",
       "         3.39295021e-06,  2.40110968e-05],\n",
       "       [ 2.29473314e+12, -3.73104755e-02, -1.00088120e-03,\n",
       "         5.72204590e-05, -5.79833984e-04, -3.82455524e+10,\n",
       "        -6.60494165e-05,  7.64911048e+09],\n",
       "       [-2.66602343e-03,  1.89362315e-03,  1.32146819e-04,\n",
       "         1.14141170e-06,  3.39295021e-06, -1.43609295e-05,\n",
       "         2.89252055e-05,  2.34110072e-06],\n",
       "       [-4.58946629e+11,  7.23243849e-03,  1.76370144e-04,\n",
       "        -5.48362732e-06,  7.43865967e-05,  7.64911048e+09,\n",
       "         1.26872549e-05, -1.52982210e+09]])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "ln.inv(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.finfo(A.dtype).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.cond(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "B = np.array([[1.0,2.0],[3.0,4.0]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 5. , -3.5],\n",
       "       [-3.5,  2.5]])"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "ln.inv(B.T @ B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 7.10542736e-15],\n",
       "       [0.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "(B.T @ B)@ln.inv(B.T @ B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.cond(B.T @ B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.cond(B.T @ B) > np.finfo((B.T @ B).dtype).eps"
   ]
  }
 ]
}